{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75766492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge, LinearRegression\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48a8da97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13334, 25) (2875, 25) (16209, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "TRAIN_PATH = \"data/processed/train_final.csv\"\n",
    "VAL_PATH = \"data/processed/val_final.csv\"\n",
    "META_PATH = \"data/satellite/image_metadata.csv\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "val_df = pd.read_csv(VAL_PATH)\n",
    "meta_df = pd.read_csv(META_PATH)\n",
    "\n",
    "print(train_df.shape, val_df.shape, meta_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caf7d255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with images: (13494, 26)\n",
      "Val with images: (2913, 26)\n"
     ]
    }
   ],
   "source": [
    "train_img_df = train_df.merge(\n",
    "    meta_df[[\"id\", \"image_path\"]],\n",
    "    on=\"id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "val_img_df = val_df.merge(\n",
    "    meta_df[[\"id\", \"image_path\"]],\n",
    "    on=\"id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Train with images:\", train_img_df.shape)\n",
    "print(\"Val with images:\", val_img_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de45ee29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "099c6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "class SatelliteDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "        img = image_transform(img)\n",
    "        return img, row[\"id\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7661d91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.fc = nn.Identity()\n",
    "resnet = resnet.to(device)\n",
    "resnet.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43cbfebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train with images: (13494, 26)\n",
      "Val with images: (2913, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>image_path_x</th>\n",
       "      <th>image_exists</th>\n",
       "      <th>log_price</th>\n",
       "      <th>spatial_bin</th>\n",
       "      <th>image_path_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9117000170</td>\n",
       "      <td>20150505T000000</td>\n",
       "      <td>268643</td>\n",
       "      <td>4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1810</td>\n",
       "      <td>9240</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>98055</td>\n",
       "      <td>47.4362</td>\n",
       "      <td>-122.187</td>\n",
       "      <td>1660</td>\n",
       "      <td>9240</td>\n",
       "      <td>/Users/khushirawat/Desktop/CDC/data/images/0.png</td>\n",
       "      <td>True</td>\n",
       "      <td>12.501142</td>\n",
       "      <td>2372_-6109</td>\n",
       "      <td>data/images/0.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6700390210</td>\n",
       "      <td>20140708T000000</td>\n",
       "      <td>245000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2788</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>98031</td>\n",
       "      <td>47.4034</td>\n",
       "      <td>-122.187</td>\n",
       "      <td>1720</td>\n",
       "      <td>3605</td>\n",
       "      <td>/Users/khushirawat/Desktop/CDC/data/images/1.png</td>\n",
       "      <td>True</td>\n",
       "      <td>12.409018</td>\n",
       "      <td>2370_-6109</td>\n",
       "      <td>data/images/1.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7212660540</td>\n",
       "      <td>20150115T000000</td>\n",
       "      <td>200000</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1720</td>\n",
       "      <td>8638</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.2704</td>\n",
       "      <td>-122.313</td>\n",
       "      <td>1870</td>\n",
       "      <td>7455</td>\n",
       "      <td>/Users/khushirawat/Desktop/CDC/data/images/2.png</td>\n",
       "      <td>True</td>\n",
       "      <td>12.206078</td>\n",
       "      <td>2364_-6116</td>\n",
       "      <td>data/images/2.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8562780200</td>\n",
       "      <td>20150427T000000</td>\n",
       "      <td>352499</td>\n",
       "      <td>2</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1240</td>\n",
       "      <td>705</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5321</td>\n",
       "      <td>-122.073</td>\n",
       "      <td>1240</td>\n",
       "      <td>750</td>\n",
       "      <td>/Users/khushirawat/Desktop/CDC/data/images/3.png</td>\n",
       "      <td>True</td>\n",
       "      <td>12.772806</td>\n",
       "      <td>2377_-6104</td>\n",
       "      <td>data/images/3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7760400350</td>\n",
       "      <td>20141205T000000</td>\n",
       "      <td>232000</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1280</td>\n",
       "      <td>13356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>98042</td>\n",
       "      <td>47.3715</td>\n",
       "      <td>-122.074</td>\n",
       "      <td>1590</td>\n",
       "      <td>8071</td>\n",
       "      <td>/Users/khushirawat/Desktop/CDC/data/images/4.png</td>\n",
       "      <td>True</td>\n",
       "      <td>12.354497</td>\n",
       "      <td>2369_-6104</td>\n",
       "      <td>data/images/4.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date   price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  9117000170  20150505T000000  268643         4       2.25         1810   \n",
       "1  6700390210  20140708T000000  245000         3       2.50         1600   \n",
       "2  7212660540  20150115T000000  200000         4       2.50         1720   \n",
       "3  8562780200  20150427T000000  352499         2       2.25         1240   \n",
       "4  7760400350  20141205T000000  232000         3       2.00         1280   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  zipcode      lat     long  \\\n",
       "0      9240     2.0           0     0  ...    98055  47.4362 -122.187   \n",
       "1      2788     2.0           0     0  ...    98031  47.4034 -122.187   \n",
       "2      8638     2.0           0     0  ...    98003  47.2704 -122.313   \n",
       "3       705     2.0           0     0  ...    98027  47.5321 -122.073   \n",
       "4     13356     1.0           0     0  ...    98042  47.3715 -122.074   \n",
       "\n",
       "   sqft_living15  sqft_lot15  \\\n",
       "0           1660        9240   \n",
       "1           1720        3605   \n",
       "2           1870        7455   \n",
       "3           1240         750   \n",
       "4           1590        8071   \n",
       "\n",
       "                                       image_path_x  image_exists  log_price  \\\n",
       "0  /Users/khushirawat/Desktop/CDC/data/images/0.png          True  12.501142   \n",
       "1  /Users/khushirawat/Desktop/CDC/data/images/1.png          True  12.409018   \n",
       "2  /Users/khushirawat/Desktop/CDC/data/images/2.png          True  12.206078   \n",
       "3  /Users/khushirawat/Desktop/CDC/data/images/3.png          True  12.772806   \n",
       "4  /Users/khushirawat/Desktop/CDC/data/images/4.png          True  12.354497   \n",
       "\n",
       "   spatial_bin       image_path_y  \n",
       "0   2372_-6109  data/images/0.png  \n",
       "1   2370_-6109  data/images/1.png  \n",
       "2   2364_-6116  data/images/2.png  \n",
       "3   2377_-6104  data/images/3.png  \n",
       "4   2369_-6104  data/images/4.png  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata\n",
    "meta_df = pd.read_csv(\"data/satellite/image_metadata.csv\")\n",
    "\n",
    "# Keep only valid images\n",
    "meta_df = meta_df[meta_df[\"status\"].isin([\"ok\", \"cached\"])]\n",
    "\n",
    "# Merge image paths into train & val\n",
    "train_img_df = train_df.merge(\n",
    "    meta_df[[\"id\", \"image_path\"]],\n",
    "    on=\"id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "val_img_df = val_df.merge(\n",
    "    meta_df[[\"id\", \"image_path\"]],\n",
    "    on=\"id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(\"Train with images:\", train_img_df.shape)\n",
    "print(\"Val with images:\", val_img_df.shape)\n",
    "train_img_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef2e1f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embeddings(df, split_name):\n",
    "    loader = DataLoader(\n",
    "        SatelliteDataset(df),\n",
    "        batch_size=32,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    embeddings = []\n",
    "    ids = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, batch_ids in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            feats = resnet(imgs)\n",
    "            embeddings.append(feats.cpu().numpy())\n",
    "            ids.extend(batch_ids.tolist())\n",
    "\n",
    "    emb = np.vstack(embeddings)\n",
    "    emb_df = pd.DataFrame(emb)\n",
    "    emb_df[\"id\"] = ids\n",
    "\n",
    "    out = f\"data/embeddings/resnet18_{split_name}_embeddings.csv\"\n",
    "    emb_df.to_csv(out, index=False)\n",
    "    print(f\"âœ… Saved {out}\")\n",
    "\n",
    "    return emb_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c56176e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_path</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9117000170</td>\n",
       "      <td>data/images/0.png</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6700390210</td>\n",
       "      <td>data/images/1.png</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7212660540</td>\n",
       "      <td>data/images/2.png</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8562780200</td>\n",
       "      <td>data/images/3.png</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7760400350</td>\n",
       "      <td>data/images/4.png</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id         image_path status\n",
       "0  9117000170  data/images/0.png     ok\n",
       "1  6700390210  data/images/1.png     ok\n",
       "2  7212660540  data/images/2.png     ok\n",
       "3  8562780200  data/images/3.png     ok\n",
       "4  7760400350  data/images/4.png     ok"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "92f4016e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'image_path', 'status']\n"
     ]
    }
   ],
   "source": [
    "print(meta_df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ada8efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_img_df columns:\n",
      "['id', 'date', 'price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'image_path_x', 'image_exists', 'log_price', 'spatial_bin', 'image_path_y']\n",
      "\n",
      "Sample rows:\n",
      "           id             date   price  bedrooms  bathrooms  sqft_living  \\\n",
      "0  9117000170  20150505T000000  268643         4       2.25         1810   \n",
      "1  6700390210  20140708T000000  245000         3       2.50         1600   \n",
      "2  7212660540  20150115T000000  200000         4       2.50         1720   \n",
      "3  8562780200  20150427T000000  352499         2       2.25         1240   \n",
      "4  7760400350  20141205T000000  232000         3       2.00         1280   \n",
      "\n",
      "   sqft_lot  floors  waterfront  view  ...  zipcode      lat     long  \\\n",
      "0      9240     2.0           0     0  ...    98055  47.4362 -122.187   \n",
      "1      2788     2.0           0     0  ...    98031  47.4034 -122.187   \n",
      "2      8638     2.0           0     0  ...    98003  47.2704 -122.313   \n",
      "3       705     2.0           0     0  ...    98027  47.5321 -122.073   \n",
      "4     13356     1.0           0     0  ...    98042  47.3715 -122.074   \n",
      "\n",
      "   sqft_living15  sqft_lot15  \\\n",
      "0           1660        9240   \n",
      "1           1720        3605   \n",
      "2           1870        7455   \n",
      "3           1240         750   \n",
      "4           1590        8071   \n",
      "\n",
      "                                       image_path_x  image_exists  log_price  \\\n",
      "0  /Users/khushirawat/Desktop/CDC/data/images/0.png          True  12.501142   \n",
      "1  /Users/khushirawat/Desktop/CDC/data/images/1.png          True  12.409018   \n",
      "2  /Users/khushirawat/Desktop/CDC/data/images/2.png          True  12.206078   \n",
      "3  /Users/khushirawat/Desktop/CDC/data/images/3.png          True  12.772806   \n",
      "4  /Users/khushirawat/Desktop/CDC/data/images/4.png          True  12.354497   \n",
      "\n",
      "   spatial_bin       image_path_y  \n",
      "0   2372_-6109  data/images/0.png  \n",
      "1   2370_-6109  data/images/1.png  \n",
      "2   2364_-6116  data/images/2.png  \n",
      "3   2377_-6104  data/images/3.png  \n",
      "4   2369_-6104  data/images/4.png  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"train_img_df columns:\")\n",
    "print(train_img_df.columns.tolist())\n",
    "\n",
    "print(\"\\nSample rows:\")\n",
    "print(train_img_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "528676fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… image_path fixed\n",
      "           id         image_path\n",
      "0  9117000170  data/images/0.png\n",
      "1  6700390210  data/images/1.png\n",
      "2  7212660540  data/images/2.png\n",
      "3  8562780200  data/images/3.png\n",
      "4  7760400350  data/images/4.png\n"
     ]
    }
   ],
   "source": [
    "# Keep the correct image path\n",
    "train_img_df[\"image_path\"] = train_img_df[\"image_path_y\"]\n",
    "val_img_df[\"image_path\"]   = val_img_df[\"image_path_y\"]\n",
    "\n",
    "# Drop confusing columns\n",
    "train_img_df = train_img_df.drop(columns=[\"image_path_x\", \"image_path_y\"])\n",
    "val_img_df   = val_img_df.drop(columns=[\"image_path_x\", \"image_path_y\"])\n",
    "\n",
    "# Final sanity check\n",
    "assert \"image_path\" in train_img_df.columns\n",
    "assert \"image_path\" in val_img_df.columns\n",
    "\n",
    "print(\"âœ… image_path fixed\")\n",
    "print(train_img_df[[\"id\", \"image_path\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbae3bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved data/embeddings/resnet18_train_embeddings.csv\n",
      "âœ… Saved data/embeddings/resnet18_val_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "train_img_emb = extract_embeddings(train_img_df, \"train\")\n",
    "val_img_emb   = extract_embeddings(val_img_df, \"val\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ab6f1ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train image embeddings: (13494, 513)\n",
      "Val image embeddings: (2913, 513)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.194103</td>\n",
       "      <td>0.283658</td>\n",
       "      <td>0.112833</td>\n",
       "      <td>0.420651</td>\n",
       "      <td>0.285698</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.046050</td>\n",
       "      <td>0.039251</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010367</td>\n",
       "      <td>0.010738</td>\n",
       "      <td>0.137973</td>\n",
       "      <td>0.246683</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218913</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>0.283981</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>9117000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.603796</td>\n",
       "      <td>0.355009</td>\n",
       "      <td>1.204026</td>\n",
       "      <td>0.008824</td>\n",
       "      <td>0.241427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.767738</td>\n",
       "      <td>0.415042</td>\n",
       "      <td>1.374431</td>\n",
       "      <td>...</td>\n",
       "      <td>1.545299</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042346</td>\n",
       "      <td>0.008975</td>\n",
       "      <td>0.051583</td>\n",
       "      <td>0.317482</td>\n",
       "      <td>3.111401</td>\n",
       "      <td>0.127758</td>\n",
       "      <td>0.499716</td>\n",
       "      <td>6700390210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.054873</td>\n",
       "      <td>0.860067</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>0.038836</td>\n",
       "      <td>0.366049</td>\n",
       "      <td>0.054929</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>0.072951</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074383</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025848</td>\n",
       "      <td>0.031698</td>\n",
       "      <td>0.373442</td>\n",
       "      <td>1.123506</td>\n",
       "      <td>1.562306</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.137207</td>\n",
       "      <td>7212660540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061988</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272383</td>\n",
       "      <td>0.685905</td>\n",
       "      <td>0.105612</td>\n",
       "      <td>0.009762</td>\n",
       "      <td>0.021206</td>\n",
       "      <td>0.018204</td>\n",
       "      <td>0.040349</td>\n",
       "      <td>0.016827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.045704</td>\n",
       "      <td>0.020665</td>\n",
       "      <td>0.426439</td>\n",
       "      <td>0.667691</td>\n",
       "      <td>0.163411</td>\n",
       "      <td>0.278357</td>\n",
       "      <td>0.140394</td>\n",
       "      <td>0.157529</td>\n",
       "      <td>0.161206</td>\n",
       "      <td>8562780200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.137182</td>\n",
       "      <td>0.329706</td>\n",
       "      <td>1.310127</td>\n",
       "      <td>0.035737</td>\n",
       "      <td>0.173745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.183540</td>\n",
       "      <td>0.291707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712315</td>\n",
       "      <td>0.028038</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099458</td>\n",
       "      <td>0.296003</td>\n",
       "      <td>3.848642</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.374227</td>\n",
       "      <td>7760400350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  0.194103  0.283658  0.112833  0.420651  0.285698  0.000000  0.046050   \n",
       "1  0.603796  0.355009  1.204026  0.008824  0.241427  0.000000  0.001300   \n",
       "2  0.054873  0.860067  0.686869  0.038836  0.366049  0.054929  0.007118   \n",
       "3  0.061988  0.000000  0.272383  0.685905  0.105612  0.009762  0.021206   \n",
       "4  0.137182  0.329706  1.310127  0.035737  0.173745  0.000000  0.000000   \n",
       "\n",
       "          7         8         9  ...       503       504       505       506  \\\n",
       "0  0.039251  0.000000  0.000000  ...  0.010367  0.010738  0.137973  0.246683   \n",
       "1  0.767738  0.415042  1.374431  ...  1.545299  0.000000  0.042346  0.008975   \n",
       "2  0.072951  0.005268  0.026211  ...  0.074383  0.000000  0.025848  0.031698   \n",
       "3  0.018204  0.040349  0.016827  ...  0.045704  0.020665  0.426439  0.667691   \n",
       "4  0.008150  0.183540  0.291707  ...  0.712315  0.028038  0.014084  0.000000   \n",
       "\n",
       "        507       508       509       510       511          id  \n",
       "0  0.000000  0.218913  0.007676  0.283981  0.001710  9117000170  \n",
       "1  0.051583  0.317482  3.111401  0.127758  0.499716  6700390210  \n",
       "2  0.373442  1.123506  1.562306  0.001235  0.137207  7212660540  \n",
       "3  0.163411  0.278357  0.140394  0.157529  0.161206  8562780200  \n",
       "4  0.099458  0.296003  3.848642  0.002644  0.374227  7760400350  \n",
       "\n",
       "[5 rows x 513 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train image embeddings:\", train_img_emb.shape)\n",
    "print(\"Val image embeddings:\", val_img_emb.shape)\n",
    "\n",
    "train_img_emb.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dc6287e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train fusion shape: (14454, 537)\n",
      "Val fusion shape: (3141, 537)\n"
     ]
    }
   ],
   "source": [
    "train_fusion_df.columns = train_fusion_df.columns.map(str)\n",
    "val_fusion_df.columns   = val_fusion_df.columns.map(str)\n",
    "print(\"Train fusion shape:\", train_fusion_df.shape)\n",
    "print(\"Val fusion shape:\", val_fusion_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87ef28cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_embedding_columns(df):\n",
    "    new_cols = []\n",
    "    for c in df.columns:\n",
    "        # if column name is a number like '0', '1', ..., '511'\n",
    "        if c.isdigit():\n",
    "            new_cols.append(f\"img_emb_{c}\")\n",
    "        else:\n",
    "            new_cols.append(c)\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "\n",
    "\n",
    "train_fusion_df = rename_embedding_columns(train_fusion_df)\n",
    "val_fusion_df   = rename_embedding_columns(val_fusion_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ada098e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embedding columns: 512\n"
     ]
    }
   ],
   "source": [
    "img_cols = [c for c in train_fusion_df.columns if c.startswith(\"img_emb_\")]\n",
    "\n",
    "print(\"Image embedding columns:\", len(img_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "24afe3c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabular: (14454, 19)\n",
      "Image: (14454, 512)\n"
     ]
    }
   ],
   "source": [
    "drop_cols = [\n",
    "    \"id\", \"price\", \"log_price\", \"date\",\n",
    "    \"image_path\", \"image_exists\"\n",
    "]\n",
    "\n",
    "tab_cols = [\n",
    "    c for c in train_fusion_df.columns\n",
    "    if c not in drop_cols and not c.startswith(\"img_emb_\")\n",
    "]\n",
    "\n",
    "X_train_tab = train_fusion_df[tab_cols]\n",
    "X_val_tab   = val_fusion_df[tab_cols]\n",
    "\n",
    "X_train_img = train_fusion_df[img_cols]\n",
    "X_val_img   = val_fusion_df[img_cols]\n",
    "\n",
    "y_train = train_fusion_df[\"log_price\"]\n",
    "y_val   = val_fusion_df[\"log_price\"]\n",
    "\n",
    "print(\"Tabular:\", X_train_tab.shape)\n",
    "print(\"Image:\", X_train_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1096447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric tabular features: (14454, 18)\n"
     ]
    }
   ],
   "source": [
    "# Keep only numeric tabular columns\n",
    "X_train_tab = X_train_tab.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "X_val_tab   = X_val_tab.select_dtypes(include=[\"int64\", \"float64\"])\n",
    "\n",
    "print(\"Numeric tabular features:\", X_train_tab.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7cd5927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_tab_scaled = scaler.fit_transform(X_train_tab)\n",
    "X_val_tab_scaled   = scaler.transform(X_val_tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "957b502e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion train: (14454, 530)\n",
      "Fusion val: (3141, 530)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train_fusion = np.hstack([X_train_tab_scaled, X_train_img.values])\n",
    "X_val_fusion   = np.hstack([X_val_tab_scaled, X_val_img.values])\n",
    "\n",
    "print(\"Fusion train:\", X_train_fusion.shape)\n",
    "print(\"Fusion val:\", X_val_fusion.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "16a431e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¥ Fusion XGBoost RÂ² (log): 0.8671113777509076\n",
      "ðŸ”¥ Fusion RMSE (log): 0.1941359577183385\n",
      "ðŸ’° RMSE (price scale): 128593.45053063401\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "fusion_xgb = XGBRegressor(\n",
    "    n_estimators=600,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "fusion_xgb.fit(X_train_fusion, y_train)\n",
    "\n",
    "val_pred = fusion_xgb.predict(X_val_fusion)\n",
    "\n",
    "r2_log = r2_score(y_val, val_pred)\n",
    "rmse_log = np.sqrt(mean_squared_error(y_val, val_pred))\n",
    "\n",
    "print(\"ðŸ”¥ Fusion XGBoost RÂ² (log):\", r2_log)\n",
    "print(\"ðŸ”¥ Fusion RMSE (log):\", rmse_log)\n",
    "val_pred_clip = np.clip(val_pred, -5, 15)\n",
    "y_val_clip = np.clip(y_val, -5, 15)\n",
    "\n",
    "rmse_price = np.sqrt(\n",
    "    mean_squared_error(\n",
    "        np.expm1(y_val_clip),\n",
    "        np.expm1(val_pred_clip)\n",
    "    )\n",
    ")\n",
    "\n",
    "print(\"ðŸ’° RMSE (price scale):\", rmse_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d30e4b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Test shape: (5404, 20)\n",
      "Test total rows: 5404\n",
      "Rows with images: 71\n",
      "âœ… Test embeddings: (71, 513)\n"
     ]
    }
   ],
   "source": [
    "TEST_PATH = \"data/processed/test2(test(1)).csv\"\n",
    "META_PATH = \"data/satellite/image_metadata.csv\"\n",
    "\n",
    "test_df = pd.read_csv(TEST_PATH)\n",
    "meta_df = pd.read_csv(META_PATH)\n",
    "\n",
    "meta_df = meta_df[meta_df[\"status\"].isin([\"ok\", \"cached\"])]\n",
    "\n",
    "print(\"âœ… Test shape:\", test_df.shape)\n",
    "test_img_df = test_df.merge(\n",
    "    meta_df[[\"id\", \"image_path\"]],\n",
    "    on=\"id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(\"Test total rows:\", test_df.shape[0])\n",
    "print(\"Rows with images:\", test_img_df[\"image_path\"].notna().sum())\n",
    "\n",
    "test_img_emb.columns = test_img_emb.columns.map(str)\n",
    "test_img_emb = rename_embedding_columns(test_img_emb)\n",
    "\n",
    "print(\"âœ… Test embeddings:\", test_img_emb.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3dfdd3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With images: (71, 21)\n",
      "Without images: (5334, 21)\n"
     ]
    }
   ],
   "source": [
    "test_with_img = test_img_df[test_img_df[\"image_path\"].notna()].copy()\n",
    "test_no_img   = test_img_df[test_img_df[\"image_path\"].isna()].copy()\n",
    "\n",
    "print(\"With images:\", test_with_img.shape)\n",
    "print(\"Without images:\", test_no_img.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fcc853b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved data/embeddings/resnet18_test_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "def rename_embedding_columns(df):\n",
    "    df = df.copy()\n",
    "    new_cols = []\n",
    "    for c in df.columns:\n",
    "        if isinstance(c, int):          # ðŸ‘ˆ FIX\n",
    "            new_cols.append(f\"img_emb_{c}\")\n",
    "        else:\n",
    "            new_cols.append(c)\n",
    "    df.columns = new_cols\n",
    "    return df\n",
    "# Image embeddings\n",
    "test_img_emb = extract_embeddings(test_with_img, \"test\")\n",
    "test_img_emb = rename_embedding_columns(test_img_emb)\n",
    "\n",
    "#X_test_img = test_img_emb[img_cols].values\n",
    "X_test_fusion = np.hstack([X_test_tab_scaled, X_test_img])\n",
    "test_pred_log = fusion_xgb.predict(X_test_fusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "205b1913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tab cols used (train âˆ© test): 18\n"
     ]
    }
   ],
   "source": [
    "# SAFELY align tabular columns between train and test\n",
    "safe_tab_cols = [c for c in tab_cols if c in test_with_img.columns]\n",
    "\n",
    "print(\"Tab cols used (train âˆ© test):\", len(safe_tab_cols))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cc03974b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With images: (71, 21)\n",
      "Without images: (5334, 20)\n",
      "Total: 5405\n"
     ]
    }
   ],
   "source": [
    "# Rows WITH images\n",
    "test_with_img = test_df.merge(\n",
    "    meta_df[[\"id\", \"image_path\"]],\n",
    "    on=\"id\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Rows WITHOUT images\n",
    "test_without_img = test_df[\n",
    "    ~test_df[\"id\"].isin(test_with_img[\"id\"])\n",
    "]\n",
    "\n",
    "print(\"With images:\", test_with_img.shape)\n",
    "print(\"Without images:\", test_without_img.shape)\n",
    "print(\"Total:\", len(test_with_img) + len(test_without_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a47619b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_tab_cols = [c for c in tab_cols if c in test_df.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d5eab22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With image\n",
    "X_test_tab_img = test_with_img[safe_tab_cols].select_dtypes(\n",
    "    include=[\"int64\", \"float64\"]\n",
    ")\n",
    "\n",
    "# Without image\n",
    "X_test_tab_noimg = test_without_img[safe_tab_cols].select_dtypes(\n",
    "    include=[\"int64\", \"float64\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "66bee948",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_tab_img_scaled = scaler.transform(X_test_tab_img)\n",
    "X_test_tab_noimg_scaled = scaler.transform(X_test_tab_noimg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d64602c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved data/embeddings/resnet18_test_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "test_img_emb = extract_embeddings(test_with_img, \"test\")\n",
    "test_img_emb = rename_embedding_columns(test_img_emb)\n",
    "\n",
    "X_test_img = test_img_emb[img_cols].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bfd3636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_fusion = np.hstack([X_test_tab_img_scaled, X_test_img])\n",
    "\n",
    "test_pred_log_img = fusion_xgb.predict(X_test_fusion)\n",
    "test_pred_log_img = np.clip(test_pred_log_img, -5, 15)\n",
    "test_pred_price_img = np.expm1(test_pred_log_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d0212d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_log_noimg = fusion_xgb.predict(\n",
    "    np.hstack([\n",
    "        X_test_tab_noimg_scaled,\n",
    "        np.zeros((X_test_tab_noimg_scaled.shape[0], X_test_img.shape[1]))\n",
    "    ])\n",
    ")\n",
    "\n",
    "test_pred_log_noimg = np.clip(test_pred_log_noimg, -5, 15)\n",
    "test_pred_price_noimg = np.expm1(test_pred_log_noimg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da932e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "febac79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… final_predictions.csv saved\n",
      "Rows: (5396, 2)\n"
     ]
    }
   ],
   "source": [
    "submission = pd.concat([\n",
    "    pd.DataFrame({\n",
    "        \"id\": test_with_img[\"id\"].values,\n",
    "        \"predicted_price\": test_pred_price_img\n",
    "    }),\n",
    "    pd.DataFrame({\n",
    "        \"id\": test_without_img[\"id\"].values,\n",
    "        \"predicted_price\": test_pred_price_noimg\n",
    "    })\n",
    "]).sort_values(\"id\")\n",
    "submission = submission.drop_duplicates(subset=[\"id\"], keep=\"first\")\n",
    "submission.to_csv(\"final_predictions.csv\", index=False)\n",
    "\n",
    "print(\"âœ… final_predictions.csv saved\")\n",
    "print(\"Rows:\", submission.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b5c48f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_df: (5404, 20)\n",
      "test_with_img: (71, 21)\n",
      "test_without_img: (5334, 20)\n",
      "submission: (5396, 2)\n",
      "Missing IDs: 0\n",
      "Extra IDs: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"test_df:\", test_df.shape)\n",
    "print(\"test_with_img:\", test_with_img.shape)\n",
    "print(\"test_without_img:\", test_without_img.shape)\n",
    "print(\"submission:\", submission.shape)\n",
    "\n",
    "missing_ids = set(test_df[\"id\"]) - set(submission[\"id\"])\n",
    "extra_ids   = set(submission[\"id\"]) - set(test_df[\"id\"])\n",
    "\n",
    "print(\"Missing IDs:\", len(missing_ids))\n",
    "print(\"Extra IDs:\", len(extra_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "24d9752c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1000102       1\n",
       "6372000280    1\n",
       "6385800030    1\n",
       "6384300020    1\n",
       "6383000690    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission[\"id\"].value_counts().head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7fac348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates in test_df: 8\n",
      "Duplicates in test_with_img: 1\n",
      "Duplicates in test_without_img: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicates in test_df:\", test_df[\"id\"].duplicated().sum())\n",
    "print(\"Duplicates in test_with_img:\", test_with_img[\"id\"].duplicated().sum())\n",
    "print(\"Duplicates in test_without_img:\", test_without_img[\"id\"].duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "447cfdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tabular test matrix: (5404, 18)\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# TABULAR-ONLY TEST PREDICTIONS\n",
    "# ===============================\n",
    "\n",
    "# Use the same tabular columns as training\n",
    "safe_tab_cols = [c for c in tab_cols if c in test_df.columns]\n",
    "\n",
    "X_test_tab = test_df[safe_tab_cols].select_dtypes(\n",
    "    include=[\"int64\", \"float64\"]\n",
    ")\n",
    "\n",
    "# Scale using TRAINED scaler\n",
    "X_test_tab_scaled = scaler.transform(X_test_tab)\n",
    "\n",
    "print(\"âœ… Tabular test matrix:\", X_test_tab_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0278be20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… tabular_xgb trained\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# ===============================\n",
    "# TRAIN TABULAR-ONLY XGBOOST\n",
    "# ===============================\n",
    "\n",
    "tabular_xgb = XGBRegressor(\n",
    "    n_estimators=600,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "tabular_xgb.fit(X_train_tab_scaled, y_train)\n",
    "\n",
    "print(\"âœ… tabular_xgb trained\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "fc2a7048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Tabular predictions ready: (5404,)\n"
     ]
    }
   ],
   "source": [
    "tabular_test_pred_log = tabular_xgb.predict(X_test_tab_scaled)\n",
    "\n",
    "# Clip for safety\n",
    "tabular_test_pred_log = np.clip(tabular_test_pred_log, -5, 15)\n",
    "\n",
    "# Convert to price scale\n",
    "tabular_test_pred_price = np.expm1(tabular_test_pred_log)\n",
    "\n",
    "print(\"âœ… Tabular predictions ready:\", tabular_test_pred_price.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a42f046a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… final_predictions.csv SAVED\n"
     ]
    }
   ],
   "source": [
    "# Fill missing with tabular predictions\n",
    "mask_missing = submission[\"predicted_price\"].isna()\n",
    "\n",
    "submission.loc[mask_missing, \"predicted_price\"] = tabular_test_pred_price[\n",
    "    mask_missing.values\n",
    "]\n",
    "\n",
    "# Final checks\n",
    "assert submission.shape[0] == test_df.shape[0]\n",
    "assert submission[\"predicted_price\"].isna().sum() == 0\n",
    "\n",
    "submission.to_csv(\"final_predictions.csv\", index=False)\n",
    "print(\"âœ… final_predictions.csv SAVED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9f9f7f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ¯ FINAL SUBMISSION READY\n"
     ]
    }
   ],
   "source": [
    "assert submission.shape[0] == test_df.shape[0]\n",
    "assert submission[\"predicted_price\"].isna().sum() == 0\n",
    "print(\"ðŸŽ¯ FINAL SUBMISSION READY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf6e31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
